<!DOCTYPE html>
<html lang="en">
<head>
    <title>ARC DP220101925: An intelligent machine modelling assistant for combinatorial optimisation</title>
    <link rel="stylesheet" href="style.css">
    <style>
        .hidden { 
            display: none; 
        }
    </style>
    <script defer src="script.js"></script>
</head>
<body>
<div class="page-wrapper">
<header>
    <div class="header-left">
        <a href="index.html">
            <span class="main-title">ARC Discovery Project (DP220101925)</span><br>
            <span class="sub-title">An intelligent machine modelling assistant for combinatorial optimisation</span>
        </a>
    </div>
    <div class="header-right">
        <img src="images/deakin.png" alt="Deakin University">
        <div class="logo-separator"></div>
        <img src="images/unimelb_logo.png" alt="The University of Melbourne">
        <div class="logo-separator"></div>
        <img src="images/MQ.jpg" alt="Macquarie University">
    </div>
</header>

<nav class="tabs">
    <button onclick="showTab('project')">Project Details & Funding</button>
    <button onclick="showTab('github')">GitHub Repositories</button>
    <button onclick="showTab('publications')">Publications</button>
    <button onclick="showTab('news')">Key Events</button>
    <button onclick="showTab('team')">Team Members</button>
</nav>
    
<main class="content-area">
        <section id="project" class="tab-content">
            <h2 class="section-heading">Australian Research Council Discovery Project (DP220101925): An intelligent machine modelling assistant for combinatorial optimisation — Deakin University</h2>
            <div class="project-grid">
        <div class="project-box">
            <h3>Summary</h3>
            <p>
                An intelligent machine modelling assistant for combinatorial optimisation. This project aims to discover key fundamental technologies for automating assistance to non-expert users in the formulation of mathematical models. Through automating the modelling of combinatorial optimization problems, this research will generate new knowledge to address the fundamental challenges of automatic mathematical modelling. This intelligent assistant will enable synthesis of new mathematical models through the utilisation of pioneering natural language processing components and novel custom-made machine-readable knowledge bases. The outcome of this research will broaden access to high-quality models by non-expert workforce and alleviate the shortage of expert mathematicians, bringing significant social and economic benefits.
            </p>
        </div>

        <div class="project-box">
            <h3>National Interest Test Statement</h3>
            <p>
                Mathematical modelling has an important role in science, business, civic services, and government operations and is traditionally conducted by expert mathematicians. However, there is a shortage of trained expert mathematicians in Australia that has a direct impact on quality and timely mathematical modelling. Optimisation modelling is a prime example of mathematical modelling that has improved business processes by saving resources or increasing efficiency for optimal outcomes. This research will make it possible for non-mathematician users to develop models tailored to their requirements through interacting with a computer. Our prototype will assist non-experts in formulating optimisation models for a range of planning, scheduling, resource allocation, timetabling problems and will benefit businesses and not-for-profit organisations. In doing so, this project will utilise a natural language processing-based agent with knowledge bases and Artificial Intelligence solutions to deliver economic and societal benefits according to Australia’s Tech Future report 2018.
            </p>
        </div>
    </div>
        </section>
        
        <section id="github" class="tab-content hidden">
            <h2 class="section-heading">GitHub Repositories</h2>
            <div class="github-grid">
                <div class="github-repo">
                    <a href="https://github.com/arc2022-deakin" target="_blank">ARC DP220101925 GitHub Repository</a>
                </div>
                <div class="github-repo">
                    <a href="https://github.com/arc2022-deakin/AgentMILO" target="_blank">AgentMILO: A Knowledge-Based Conversational Agent for MILP Modeling</a>
                </div>
                <div class="github-repo">
                    <a href="https://github.com/eabdullin/optimouse-quest/" target="_blank">The dataset from the paper "Synthetic Dialogue Dataset Generation using LLM Agents" by Abdullin et al.</a>
                </div>
            </div>
        </section>
        
        <section id="publications" class="tab-content hidden">
            <h2 class="section-heading">Publications</h2>
                <div class="publication-card">
                    <h3>📄 AgentMILO: A Knowledge-Based Framework for Complex MILP Modelling Conversations with LLMs</h3>
                        <p class="authors"><strong>Authors:</strong> Jyotheesh Gaddam, Lele Zhang, Vicky Mak-Hau, John Yearwood, Bahadorreza Ofoghi, Diego Molla-Aliod</p>
                        <p class="abstract"><strong>Abstract:</strong> This paper presents AgentMILO, an LLM-based conversational agent designed to assist non-expert users in modelling complex Mixed-Integer Linear Programming (MILP) problems, with a focus on production planning and single-traveller routing problem types. By incorporating expert designed knowledge graphs, AgentMILO improves the problem modelling process by guiding users through asking relevant questions to elicit problem specifications from users and formulation of precise MILP models. Through experiments with ten distinct auto-answering agents acting as users, we compared AgentMILO against a general LLM agent without knowledge graphs. The results show that AgentMILO consistently outperforms the general LLM model in clarity in guiding users, question quality, and ease of interaction, while also delivering more precise MILP formulations. In contrast, the general model struggled with inconsistent performance and frequent failures in guiding users effectively. AgentMILO's architecture allows for integration into various domains, with the potential to utilise expert knowledge to design new knowledge graphs tailored to specific scenarios.</p>
                    <div class="publication-links">
                        <a href="#" target="_blank">🔗 Read Paper</a>
                        <a href="https://github.com/arc2022-deakin/AgentMILO" target="_blank">💻 GitHub Repository</a>
                    </div>
                </div>
                <div class="publication-card">
                    <h3>📄 Investigating Answer Validation Using Noise Identification and Classification in Goal-Oriented Dialogues</h3>
                        <p class="authors"><strong>Authors:</strong> Sara Mirabi, Bahadorreza Ofoghi, John Yearwood, Diego Molla-Aliod, Vicky Mak-Hau</p>
                        <p class="abstract"><strong>Abstract:</strong> Goal-oriented conversational systems based on large language models (LLMs) provide the potential capability to gather the necessary requirements for solving tasks or developing solutions. However, in real-world scenarios, non-expert users may respond incorrectly to dialogue questions, which can impede the system’s effectiveness in eliciting accurate information. This paper presents a novel approach to detecting and categorizing noisy answers in goal-oriented conversations, with a focus on modeling linear programming problems. Using a current LLM, Gemini, we develop multi-agent synthetic conversations based on problem statements from the benchmark optimization modeling dataset NL4Opt to generate dialogues in the presence of noisy answers too. Our experiments show the LLM is not sufficiently equipped with the capabilities to detect noisy answers and hence, in almost 59% of the cases where there is a noisy answer, the LLM continues with the conversation without any attempts at resolving</p>
                    <div class="publication-links">
                        <a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0013304000003890" target="_blank">🔗 Read Paper</a>
                    </div>
                </div>
                <div class="publication-card">
                    <h3>📄 Synthetic Dialogue Dataset Generation using LLM Agents</h3>
                        <p class="authors"><strong>Authors:</strong> Yelaman Abdullin, Diego Molla-Aliod, Bahadorreza Ofoghi, John Yearwood, Qingyang Li</p>
                        <p class="abstract"><strong>Abstract:</strong> Linear programming (LP) problems are pervasive in real-life applications. However, despite their apparent simplicity, an untrained user may find it difficult to determine the linear model of their specific problem. We envisage the creation of a goal-oriented conversational agent that will engage in conversation with the user to elicit all information required so that a subsequent agent can generate the linear model. In this paper, we present an approach for the generation of sample dialogues that can be used to develop and train such a conversational agent. Using prompt engineering, we develop two agents that "talk" to each other, one acting as the conversational agent, and the other acting as the user. Using a set of text descriptions of linear problems from NL4Opt available to the user only, the agent and the user engage in conversation until the agent has retrieved all key information from the original problem description. We also propose an extrinsic evaluation of the dialogues by assessing how well the summaries generated by the dialogues match the original problem descriptions. We conduct human and automatic evaluations, including an evaluation approach that uses GPT-4 to mimic the human evaluation metrics. The evaluation results show an overall good quality of the dialogues, though research is still needed to improve the quality of the GPT-4 evaluation metrics. The resulting dialogues, including the human annotations of a subset, are available to the research community. The conversational agent used for the generation of the dialogues can be used as a baseline.</p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2401.17461" target="_blank">🔗 Read Paper</a>
                        <a href="https://github.com/eabdullin/optimouse-quest/" target="_blank">💻 GitHub Repository</a>
                    </div>
                </div>
                <div class="publication-card">
                    <h3>📄 Synthesizing mixed-integer linear programming models from natural language descriptions</h3>
                        <p class="authors"><strong>Authors:</strong> Qingyang Li, Lele Zhang, Vicky Mak-Hau</p>
                        <p class="abstract"><strong>Abstract:</strong> Numerous real-world decision-making problems can be formulated and solved using Mixed-Integer Linear Programming (MILP) models. However, the transformation of these problems into MILP models heavily relies on expertise in operations research and mathematical optimization, which restricts non-experts' accessibility to MILP. To address this challenge, we propose a framework for automatically formulating MILP models from unstructured natural language descriptions of decision problems, which integrates Large Language Models (LLMs) and mathematical modeling techniques. This framework consists of three phases: i) identification of decision variables, ii) classification of objective and constraints, and iii) finally, generation of MILP models. In this study, we present a constraint classification scheme and a set of constraint templates that can guide the LLMs in synthesizing a complete MILP model. After fine-tuning LLMs, our approach can identify and synthesize logic constraints in addition to classic demand and resource constraints. The logic constraints have not been studied in existing work. To evaluate the performance of the proposed framework, we extend the NL4Opt dataset with more problem descriptions and constraint types, and with the new dataset, we compare our framework with one-step model generation methods offered by LLMs. The experimental results reveal that with respect to the accuracies of generating the correct model, objective, and constraints, our method which integrates constraint classification and templates with LLMs significantly outperforms the others. The prototype system that we developed has a great potential to capture more constraints for more complex MILPs. It opens up opportunities for developing training tools for operations research practitioners and has the potential to be a powerful tool for automatic decision problem modeling and solving in practice.</p>
                    <div class="publication-links">
                        <a href="https://arxiv.org/pdf/2311.15271" target="_blank">🔗 Read Paper</a>
                    </div>
                </div>
                <div class="publication-card">
                    <h3>📄 Knowledge representation of mathematical optimization problems and constructs for modeling</h3>
                        <p class="authors"><strong>Authors:</strong> Bahadorreza Ofoghi, John Yearwood</p>
                        <p class="abstract"><strong>Abstract:</strong> We introduce two new knowledge bases that we have developed to categorize mixed-integer linear programming (MILP) problems and standardize the element definitions of MILP models. MILP is a commonly used mathematical programming technique for modeling and solving real-life scheduling, routing, planning, resource allocation, and timetabling optimization problems providing optimized business solutions for industry sectors such as manufacturing, agriculture, defense, healthcare, medicine, energy, finance, and transportation among others. Despite the numerous real-life combinatorial optimization problems (COPs) found and solved, and many yet to be discovered and formulated, the number of types of constraints (the building blocks of a MILP) is relatively small. In the search for a uniform categorization of MILP problems and a machine-readable knowledge representation structure for MILP models, we have developed an optimization modeling tree (OMT) and a MILP model ontology. The two knowledge structures can serve as a standardized, uniform representation in understanding MILP problems and developing MILP models for combinatorial business optimization problems. While there are several algebraic modeling languages (AMLs) for developing and solving MILP models, the semantic correctness of such models cannot be guaranteed using the syntactic grammar of such AMLs. The MILP model ontology will act as the main resource for semantic validation of MILP models through ontology instantiations and axiom assertions.</p>
                    <div class="publication-links">
                        <a href="https://www.sciencedirect.com/science/article/pii/S095070512300730X" target="_blank">🔗 Read Paper</a>
                    </div>
                </div>
        </section>

        <section id="news" class="tab-content hidden">
            <h2 class="section-heading">Key Events</h2>
            <div class="timeline">
        
                <!-- 📆 2026 -->
                <button class="year-toggle" onclick="toggleYear('y2026')">▼ 2026</button>
                <div class="year-group" id="y2026">
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📆</div>
                        <div class="timeline-content">
                            <strong>15 Feb 2026</strong> – ARC Discovery Project DP220101925 is scheduled to conclude.
                        </div>
                    </div>
                </div>
        
                <!-- 📆 2025 -->
                <button class="year-toggle" onclick="toggleYear('y2025')">▼ 2025</button>
                <div class="year-group" id="y2025">
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>21 March 2025</strong> – <em>Dr Jyotheesh Gaddam</em> presented <strong>“AgentMILO: A Knowledge-Based Framework for Complex MILP Modelling Conversations with LLMs”</strong> at ICCAE 2025, Perth, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📄</div>
                        <div class="timeline-content">
                            <strong>February 2025</strong> – <em>Sara Mirabi et al.</em> published a paper titled <strong>“Investigating Answer Validation Using Noise Identification and Classification in Goal-Oriented Dialogues”</strong> on ICAART 2025.<br>
                            <strong>DOI:</strong> <a href="https://doi.org/10.5220/0013304000003890" target="_blank">https://doi.org/10.5220/0013304000003890</a>
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>25 February 2025</strong> – <em>Sara Mirabi</em> presented <strong>“Investigating Answer Validation Using Noise Identification and Classification in Goal-Oriented Dialogues”</strong> at ICAART 2025, Porto, Portugal.<br>
                        </div>
                    </div>
                </div>        
                <!-- 📆 2024 -->
                <button class="year-toggle" onclick="toggleYear('y2024')">▼ 2024</button>
                <div class="year-group" id="y2024">
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>October 2024</strong> – <em>Qingyang Li</em> gave a talk at INFORMS 2024 on <strong>“Synthesizing Mixed-Integer Linear Programming Models from Natural Language Descriptions”</strong>, Seattle, Washington, USA.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🧾</div>
                        <div class="timeline-content">
                            <strong>July 2024</strong> – <em>Qingyang Li</em> gave an oral and poster presentation titled <strong>“Synthesizing Mixed-Integer Linear Programming Models from Natural Language Descriptions”</strong> at OPTIMA-CON 2024, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🏫</div>
                        <div class="timeline-content">
                            <strong>2 May 2024</strong> – <em>A/Prof Lele Zhang</em> delivered a talk at the School’s Colloquium, The University of Melbourne, titled <strong>“Automatic Modelling of Mixed-Integer Linear Programs Assisted by Large Language Models”, Melbourne, Australia.</strong>
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">👨‍🔬</div>
                        <div class="timeline-content">
                            <strong>8 April 2024</strong> – <em>Dr. Jyotheesh Gaddam</em> commenced his role as a Postdoctoral Research Fellow at Deakin University, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📄</div>
                        <div class="timeline-content">
                            <strong>30 Jan 2024</strong> – <em>Yelaman Abdullin et al.</em> published a paper titled <strong>“Synthetic Dialogue Dataset Generation Using LLM Agents”</strong> on arXiv.<br>
                            <strong>DOI:</strong> <a href="https://arxiv.org/abs/2401.17461" target="_blank">arXiv:2401.17461</a>
                        </div>
                    </div>
                </div>
        
                <!-- 📆 2023 -->
                <button class="year-toggle" onclick="toggleYear('y2023')">▼ 2023</button>
                <div class="year-group" id="y2023">
                    <div class="timeline-item animate">
                        <div class="timeline-icon">👨‍🔬</div>
                        <div class="timeline-content">
                            <strong>December 2023</strong> – <em>Dr. Thuseethan Selvarajah</em> concluded his role as a Postdoctoral Research Fellow at Deakin University, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>December 2023</strong> – <em>Qingyang Li</em> presented <strong>“Synthesizing Mixed-Integer Linear Programming Models from Natural Language Descriptions”</strong> at the AI-OPT 2023 Workshop, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>6 December 2023</strong> – <em>Yelaman Abdullin</em> presented <strong>“Synthetic Dialogue Dataset Generation Using LLM Agents”</strong> at the GEM Workshop (EMNLP 2023), Singapore.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎙️</div>
                        <div class="timeline-content">
                            <strong>30 November 2023</strong> – <em>Yelaman Abdullin</em> presented <strong>“Synthetic Dialogue Dataset Generation Using LLM Agents”</strong> at ALTA 2023, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📄</div>
                        <div class="timeline-content">
                            <strong>26 November 2023</strong> – <em>Qingyang Li et al.</em> published a paper titled <strong>“Synthesizing Mixed-Integer Linear Programming Models from Natural Language Descriptions”</strong> on arXiv.<br>
                            <strong>DOI:</strong> <a href="https://arxiv.org/pdf/2311.15271" target="_blank">https://arxiv.org/pdf/2311.15271</a>
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📄</div>
                        <div class="timeline-content">
                            <strong>25 November 2023</strong> – <em>Sr Lect Bahadorreza Ofoghi et al.</em> published a paper titled <strong>“Knowledge representation of mathematical optimization problems and constructs for modeling”</strong> on Knowledge-Based Systems.<br>
                            <strong>DOI:</strong> <a href="https://doi.org/10.1016/j.knosys.2023.110980" target="_blank">https://doi.org/10.1016/j.knosys.2023.110980</a>
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎓</div>
                        <div class="timeline-content">
                            <strong>8 November 2023</strong> – <em>Sara Mirabi</em> began her PhD at Deakin University, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎓</div>
                        <div class="timeline-content">
                            <strong>16 February 2023</strong> – <em>Qingyang Li</em> began her PhD at The University of Melbourne, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">🎓</div>
                        <div class="timeline-content">
                            <strong>1 February 2023</strong> – <em>Yelaman Abdullin</em> began his PhD at Macquarie University, Sydney, Australia.
                        </div>
                    </div>
                </div>
        
                <!-- 📆 2022 -->
                <button class="year-toggle" onclick="toggleYear('y2022')">▼ 2022</button>
                <div class="year-group" id="y2022">
                    <div class="timeline-item animate">
                        <div class="timeline-icon">👨‍🔬</div>
                        <div class="timeline-content">
                            <strong>November 2022</strong> – <em>Dr. Thuseethan Selvarajah</em> commenced his role as a Postdoctoral Research Fellow at Deakin University, Melbourne, Australia.
                        </div>
                    </div>
                    <div class="timeline-item animate">
                        <div class="timeline-icon">📆</div>
                        <div class="timeline-content">
                            <strong>2 June 2022</strong> – ARC Discovery Project DP220101925 officially commenced.
                        </div>
                    </div>
                </div>
        
            </div>
        </section>


    
        <section id="team" class="tab-content hidden">
            <h2 class="section-heading">Chief Investigators</h2>
            <div class="ci-grid">
                <div class="member">
                    <span class="role-badge role-former" data-tooltip="Chief Investigator – Former Lead">🏁 Former Lead CI</span>
                    <img src="images/john.jpeg" alt="John Yearwood">
                    <h3>Prof John Yearwood</h3>
                    <p>Emeritus Professor, Faculty of Science Engineering and Built Environment/Office of the Executive Dean Science, Engineering and Built Environment, Deakin University, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:john.yearwood@deakin.edu.au">john.yearwood@deakin.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-lead" data-tooltip="Chief Investigator – Project Lead">🎖️ Lead CI</span>
                    <img src="images/vicky.png" alt="Vicky Mak-Hau">
                    <h3>Prof Vicky Mak-Hau</h3>
                    <p>Professor, Faculty of Science Engineering and Built Environment/School of Information Technology, Deakin University, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:vicky.mak@deakin.edu.au">vicky.mak@deakin.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-ci" data-tooltip="Chief Investigator">🎯 CI</span>
                    <img src="images/bahador.png" alt="Bahadorreza Ofoghi">
                    <h3>Sr Lect Bahadorreza Ofoghi</h3>
                    <p>Senior Lecturer, Information Technology, Faculty of Science Engineering and Built Environment/School of Information Technology, Deakin University, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:b.ofoghi@deakin.edu.au">b.ofoghi@deakin.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-ci" data-tooltip="Chief Investigator">🎯 CI</span>
                    <img src="images/joyce.jpeg" alt="Lele Zhang">
                    <h3>A/Prof Lele Zhang</h3>
                    <p>Associate Professor, School of Mathematics and Statistics, The University of Melbourne, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:lele.zhang@unimelb.edu.au">lele.zhang@unimelb.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-ci" data-tooltip="Chief Investigator">🎯 CI</span>
                    <img src="images/diego.webp" alt="Diego Molla-Aliod">
                    <h3>Sr Lect Diego Molla-Aliod</h3>
                    <p>Senior Lecturer, School of Computing, Macquarie University, Sydney, Australia</p>
                    <p>📧 <a href="mailto:diego.molla-aliod@mq.edu.au">diego.molla-aliod@mq.edu.au</a></p>
                </div>
            </div>
            <h2 class="section-heading">Post-Doctoral Fellow</h2>
            <div class="postdoc-grid">
                <div class="member">
                    <span class="role-badge role-current-postdoc" data-tooltip="Postdoctoral Fellow since April 2024">🧪 Current Postdoc</span>
                    <img src="images/jyo.jpg" alt="Jyotheesh Gaddam">
                    <h3>Dr Jyotheesh Gaddam</h3>
                    <p>Postdoctoral Research Fellow, Faculty of Science Engineering and Built Environment/School of Information Technology, Deakin University, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:j.gaddam@deakin.edu.au">j.gaddam@deakin.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-former-postdoc" data-tooltip="Former Postdoctoral Fellow (Nov 2022 – Dec 2023)">👨‍🔬 Former Postdoc</span>
                    <img src="images/Thuseethan.jpg" alt="Thuseethan Selvarajah">
                    <h3>Dr Thuseethan Selvarajah</h3>
                    <p>Postdoctoral Research Fellow, Faculty of Science Engineering and Built Environment/School of Information Technology, Deakin University, Melbourne, Australia</p>
                </div>
            </div>
            <h2 class="section-heading">PhD Students</h2>
            <div class="phd-grid">
                <div class="member">
                    <span class="role-badge role-phd" data-tooltip="PhD Researcher">🎓 PhD</span>
                    <img src="images/Qingyang-Li.jpg" alt="Qingyang Li">
                    <h3>Qingyang Li</h3>
                    <p>Graduate Researcher, The University of Melbourne, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:qingyang.li5@student.unimelb.edu.au">qingyang.li5@student.unimelb.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-phd" data-tooltip="PhD Researcher">🎓 PhD</span>
                    <img src="images/sara.jpeg" alt="Sara Mirabi">
                    <h3>Sara Mirabi</h3>
                    <p>Graduate Researcher, Deakin University, Melbourne, Australia</p>
                    <p>📧 <a href="mailto:s222496341@deakin.edu.au">s222496341@deakin.edu.au</a></p>
                </div>
                <div class="member">
                    <span class="role-badge role-phd" data-tooltip="PhD Researcher">🎓 PhD</span>
                    <img src="images/yelaman.jpeg" alt="Yelaman Abdullin">
                    <h3>Yelaman Abdullin</h3>
                    <p>Graduate Researcher, Macquarie University, Sydney, Australia</p>
                    <p>📧 <a href="mailto:yelaman.abdullin@hdr.mq.edu.au">yelaman.abdullin@hdr.mq.edu.au</a></p>
                </div>
            </div>
        </section>
</main>

    <footer>
        <p>&copy; 2025 ARC DP220101925 Team</p>
    </footer>

    <script>
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('show');
                }
            });
        }, { threshold: 0.1 });

        document.querySelectorAll('.timeline-item').forEach(item => {
            observer.observe(item);
        });

        function toggleYear(id) {
            const group = document.getElementById(id);
            const btn = event.target;
            if (group.style.display === 'none') {
                group.style.display = 'block';
                btn.innerText = btn.innerText.replace('▶', '▼');
            } else {
                group.style.display = 'none';
                btn.innerText = btn.innerText.replace('▼', '▶');
            }
        }

        document.querySelectorAll('.year-group').forEach(group => group.style.display = 'block');
    </script>

</body>
</html>
